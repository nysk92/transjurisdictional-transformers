{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f1b717",
   "metadata": {},
   "source": [
    "# Evaluation Script\n",
    "\n",
    "With the vectors from tfidf, fastText and BERT prepared and saved from previous notebooks, we can now evaluate the performance based on any prepared answer keys of correct legislation sections pairs.\n",
    "\n",
    "The metric to be used will be Recall@k. The scripts below can compute different values of k, but for simplicity, this project will focus on k=3. Recall@3 will be a good proxy for a user being able to see the ideal result instantly without having to scroll down.\n",
    "\n",
    "**Important Note:** When evaluating, ensure that the entries for the output jurisdiction `juris_B` are all below that of the input jurisdiction `juris_A`, as the evaluation scripts make the assumption that they are ordered that way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a99577",
   "metadata": {},
   "source": [
    "The outputs below demo based on data for the SG Copyright Act and UK CDPA, but do note as mentioned, the data files containing legislation content will not be in the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a206715",
   "metadata": {},
   "source": [
    "### Imports and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b563a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e6cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'sec'\n",
    "required_input_cols = [id_col, 'title', 'url', 'cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05eca90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "juris_A = 'sg'\n",
    "juris_B = 'uk'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b70354",
   "metadata": {},
   "source": [
    "Specify Evaluation Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b382565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with copyright legislation data\n",
    "\n",
    "# params to feed into eval function\n",
    "params = {}\n",
    "params['law_topic'] = 'copyright' # legal topic\n",
    "params['data_file'] = '../data/clean/copyright/sg_uk_copyright.csv' # this data file will not be pushed to git repo \n",
    "params['ak_file'] = '../data/answer-keys/copyright_ak.csv' # answer key file\n",
    "params['output_jurisdiction'] = juris_B \n",
    "params['ks_to_try'] = [1, 3, 5]\n",
    "params['vector_files'] = [\n",
    "    '../data/vectors/copyright/cp_sg_uk_vecs_tfidf.npy',\n",
    "    '../data/vectors/copyright/cp_sg_uk_vecs_ft.npy',\n",
    "    '../data/vectors/copyright/cp_sg_uk_vecs_bert_mlm.npy'\n",
    "]\n",
    "\n",
    "baseline_filepath = '../data/baselines/sg_uk_copyright_levdists.csv' # file containg levenshtein edit distance of titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c9e7c",
   "metadata": {},
   "source": [
    "### Evalution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942f1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(result_vecs, div_index, answer_key, k=3, get_wrongs=True):\n",
    "    \"\"\"\n",
    "    This function evaluates recall @ k. Default of k=3.\n",
    "    \n",
    "    The input of result_vecs is the dataframe of vectors \n",
    "    that have the section as the index, e.g. 'sg_5'\n",
    "    while the values of the row represents the vectors.\n",
    "    \n",
    "    Take note of the index number that separates the two jurisdictions, div_index.,\n",
    "    which would be the numeric index of the first entry of jurisdiction 2 in the result_vecs.\n",
    "    \"\"\"\n",
    "    \n",
    "    answers_in_top_k = 0\n",
    "    wrongs = []\n",
    "    \n",
    "    # separate first and second jurisdictions into j1 and j2\n",
    "    j1_vecs = result_vecs[:div_index]\n",
    "    j2_vecs = result_vecs[div_index:]\n",
    "    \n",
    "    for i, _ in answer_key.iterrows():\n",
    "        # the tested section will be in column 0 of answer keys\n",
    "        test_sec = answer_key.iloc[i,0]\n",
    "        # the correct corresponding section will be in column 1 of answer keys\n",
    "        correct_sec = answer_key.iloc[i,1]\n",
    "        # get the candidate cosine similarities between \n",
    "        # the tested section and the candidate sections of the other jurisdiction\n",
    "        cos_sims = cosine_similarity(\n",
    "            [j1_vecs.loc[test_sec]],\n",
    "            j2_vecs)\n",
    "        \n",
    "        # get the top k results and get their respective sections\n",
    "        j2_result_ids = (-cos_sims)[0].argsort()[:k]\n",
    "        j2_result_secs = j2_vecs.iloc[j2_result_ids].index\n",
    "\n",
    "        if correct_sec in j2_result_secs:\n",
    "            answers_in_top_k += 1\n",
    "        else:\n",
    "            wrongs.append((test_sec, correct_sec, j2_result_secs.values))\n",
    "    \n",
    "    score = round((answers_in_top_k / answer_key.shape[0]), 2)\n",
    "    \n",
    "    if get_wrongs:\n",
    "        return {'score': score,\n",
    "                'wrongs': wrongs}\n",
    "    else:\n",
    "        return f'score {score}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe81da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(law_topic, data_file, ak_file, vector_files, ks_to_try, output_jurisdiction, get_wrongs=True):\n",
    "    data = pd.read_csv(data_file)\n",
    "    answer_key = pd.read_csv(ak_file)\n",
    "    juris_split_id = data[data[id_col].str.contains(output_jurisdiction)].first_valid_index()\n",
    "    print(juris_split_id)\n",
    "    print(f'Evaluating results for {law_topic}...', '\\n\\n')\n",
    "    \n",
    "    for vector_file in vector_files:\n",
    "        for k in ks_to_try:\n",
    "            vector_file_shortname = vector_file.rsplit('/', 1)[-1]\n",
    "            print(f'Getting recall at {k} results for vector file {vector_file_shortname}...')\n",
    "            all_sent_vecs = np.load(vector_file)\n",
    "            print(f'Vector file of shape {all_sent_vecs.shape}...')\n",
    "            result_vecs = pd.DataFrame(all_sent_vecs, index=data[id_col])\n",
    "            print(evaluate(result_vecs, div_index=juris_split_id, \n",
    "                           answer_key=answer_key, k=k, get_wrongs=get_wrongs))\n",
    "            print('\\n\\n\\n')\n",
    "    \n",
    "    print('Evaluation complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821d40f",
   "metadata": {},
   "source": [
    "The levenshtein (edit) distance function works slightly differently because there can be many title matches with the same edit distance, to make the baseline more lenient, as long as the answers edit distance is in the top k edit distances, it counts as a hit. \n",
    "\n",
    "It is ok to be lenient with the baseline as it would make beating the baseline more challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3575fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_levdis(result_levdis, output_juris, ak_filepath, data_filepath, k=3):\n",
    "    \"\"\"\n",
    "    This function evaluates recall @ k. Default of k=3.\n",
    "    \n",
    "    The input of result_vecs is the dataframe of lev distances \n",
    "    that have the section as the index, e.g. 'sg_5'\n",
    "    while the values of the row represents the lev distance,\n",
    "    \n",
    "    Take note of the index number that separates the two jurisdictions, div_index.,\n",
    "    which would be the numeric index of the first entry of jurisdiction 2.\n",
    "    \"\"\"\n",
    "    answer_key = pd.read_csv(ak_filepath)\n",
    "    data = pd.read_csv(data_filepath)\n",
    "    \n",
    "    div_index = data[data[id_col].str.contains(output_juris)].first_valid_index()\n",
    "    answers_in_top_k = 0\n",
    "    wrongs = []\n",
    "    \n",
    "    for i, _ in answer_key.iterrows():\n",
    "        # the tested section will be in column 0 of answer keys\n",
    "        test_sec = answer_key.iloc[i,0]\n",
    "        # the correct corresponding section will be in column 1 of answer keys\n",
    "        correct_sec = answer_key.iloc[i,1]\n",
    "        # get the shortest k lev distances\n",
    "        shortest_k_levdis = result_levdis.loc[test_sec][div_index:].sort_values()[:k].values\n",
    "        # get the lev distance of the correct j2 sec in the answer key\n",
    "        correct_sec_levdis = result_levdis.loc[test_sec, correct_sec]\n",
    "        \n",
    "        # comparing the actual distance as there may be many tied distances\n",
    "        if correct_sec_levdis in shortest_k_levdis:\n",
    "            answers_in_top_k += 1\n",
    "        else:\n",
    "            shortest_k_levdis_secs = result_levdis.loc[test_sec][div_index:].sort_values()[:k].index\n",
    "            wrongs.append((test_sec, correct_sec, shortest_k_levdis_secs))\n",
    "    \n",
    "    return {'score': round((answers_in_top_k / answer_key.shape[0]), 2),\n",
    "            'wrongs': wrongs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a8cd4",
   "metadata": {},
   "source": [
    "### Getting Baseline Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734a4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_levdis_filepath = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6659ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_levdis = pd.read_csv(baseline_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065e6a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec</th>\n",
       "      <th>sg_1</th>\n",
       "      <th>sg_2</th>\n",
       "      <th>sg_3</th>\n",
       "      <th>sg_4</th>\n",
       "      <th>sg_5</th>\n",
       "      <th>sg_6</th>\n",
       "      <th>sg_7</th>\n",
       "      <th>sg_7A</th>\n",
       "      <th>sg_8</th>\n",
       "      <th>...</th>\n",
       "      <th>uk_297C</th>\n",
       "      <th>uk_297D</th>\n",
       "      <th>uk_298</th>\n",
       "      <th>uk_299</th>\n",
       "      <th>uk_301</th>\n",
       "      <th>uk_302</th>\n",
       "      <th>uk_303</th>\n",
       "      <th>uk_304</th>\n",
       "      <th>uk_305</th>\n",
       "      <th>uk_306</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sg_1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>42</td>\n",
       "      <td>84</td>\n",
       "      <td>44</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sg_2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>43</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "      <td>69</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sg_3</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>36</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sg_4</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sg_5</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sec  sg_1  sg_2  sg_3  sg_4  sg_5  sg_6  sg_7  sg_7A  sg_8  ...  uk_297C  \\\n",
       "0  sg_1     0    10    21    45    30    18    11     49    10  ...       71   \n",
       "1  sg_2    10     0    14    47    33    19     8     48    10  ...       72   \n",
       "2  sg_3    21    14     0    41    22    15    22     43    21  ...       63   \n",
       "3  sg_4    45    47    41     0    41    42    45     49    48  ...       60   \n",
       "4  sg_5    30    33    22    41     0    29    31     45    32  ...       60   \n",
       "\n",
       "   uk_297D  uk_298  uk_299  uk_301  uk_302  uk_303  uk_304  uk_305  uk_306  \n",
       "0       42      84      44      65      45      32       9      11       0  \n",
       "1       43      84      42      69      45      32      10      11      10  \n",
       "2       39      78      36      63      42      29      21      19      21  \n",
       "3       44      70      44      55      47      43      49      46      45  \n",
       "4       37      72      37      59      42      33      33      31      30  \n",
       "\n",
       "[5 rows x 781 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_levdis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858c7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_levdis.set_index(id_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102d8ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.35,\n",
       " 'wrongs': [('sg_7A',\n",
       "   'uk_3A',\n",
       "   Index(['uk_3', 'uk_271', 'uk_243'], dtype='object')),\n",
       "  ('sg_28', 'uk_12', Index(['uk_13B', 'uk_13A', 'uk_14'], dtype='object')),\n",
       "  ('sg_29', 'uk_57', Index(['uk_13A', 'uk_14', 'uk_13B'], dtype='object')),\n",
       "  ('sg_36', 'uk_30', Index(['uk_70', 'uk_148', 'uk_68'], dtype='object')),\n",
       "  ('sg_38', 'uk_45', Index(['uk_148', 'uk_70', 'uk_122'], dtype='object')),\n",
       "  ('sg_38A', 'uk_28A', Index(['uk_172', 'uk_54', 'uk_175'], dtype='object')),\n",
       "  ('sg_65', 'uk_31', Index(['uk_63', 'uk_89', 'uk_68'], dtype='object')),\n",
       "  ('sg_120', 'uk_99', Index(['uk_199', 'uk_108', 'uk_231'], dtype='object')),\n",
       "  ('sg_136', 'uk_107', Index(['uk_250', 'uk_304', 'uk_193'], dtype='object')),\n",
       "  ('sg_140M',\n",
       "   'uk_109',\n",
       "   Index(['uk_135B', 'uk_162', 'uk_100'], dtype='object')),\n",
       "  ('sg_188', 'uk_84', Index(['uk_190', 'uk_182', 'uk_294'], dtype='object')),\n",
       "  ('sg_193F', 'uk_56', Index(['uk_31', 'uk_15A', 'uk_170'], dtype='object')),\n",
       "  ('sg_200', 'uk_253C', Index(['uk_45', 'uk_5A', 'uk_158'], dtype='object'))]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_levdis(result_levdis, juris_B, params['ak_file'], params['data_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22349737",
   "metadata": {},
   "source": [
    "### Using Evaluation Function\n",
    "\n",
    "Works with the saved tfidf, fastText and BERT vectors (npy files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7db44180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "Evaluating results for copyright... \n",
      "\n",
      "\n",
      "Getting recall at 1 results for vector file cp_sg_uk_vecs_tfidf.npy...\n",
      "Vector file of shape (780, 32516)...\n",
      "score 0.8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 3 results for vector file cp_sg_uk_vecs_tfidf.npy...\n",
      "Vector file of shape (780, 32516)...\n",
      "score 0.8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 5 results for vector file cp_sg_uk_vecs_tfidf.npy...\n",
      "Vector file of shape (780, 32516)...\n",
      "score 0.9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 1 results for vector file cp_sg_uk_vecs_ft.npy...\n",
      "Vector file of shape (780, 100)...\n",
      "score 0.25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 3 results for vector file cp_sg_uk_vecs_ft.npy...\n",
      "Vector file of shape (780, 100)...\n",
      "score 0.4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 5 results for vector file cp_sg_uk_vecs_ft.npy...\n",
      "Vector file of shape (780, 100)...\n",
      "score 0.45\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 1 results for vector file cp_sg_uk_vecs_bert_mlm.npy...\n",
      "Vector file of shape (780, 768)...\n",
      "score 0.4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 3 results for vector file cp_sg_uk_vecs_bert_mlm.npy...\n",
      "Vector file of shape (780, 768)...\n",
      "score 0.55\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 5 results for vector file cp_sg_uk_vecs_bert_mlm.npy...\n",
      "Vector file of shape (780, 768)...\n",
      "score 0.55\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(**params, get_wrongs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f17ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "Evaluating results for copyright... \n",
      "\n",
      "\n",
      "Getting recall at 1 results for vector file cp_sg_uk_vecs_tfidf.npy...\n",
      "Vector file of shape (780, 32516)...\n",
      "{'score': 0.8, 'wrongs': [('sg_29', 'uk_57', array(['uk_12'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_296ZE'], dtype=object)), ('sg_160', 'uk_118', array(['uk_119'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_102'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 3 results for vector file cp_sg_uk_vecs_tfidf.npy...\n",
      "Vector file of shape (780, 32516)...\n",
      "{'score': 0.8, 'wrongs': [('sg_29', 'uk_57', array(['uk_12', 'uk_104', 'uk_13B'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_296ZE', 'uk_107', 'uk_198'], dtype=object)), ('sg_160', 'uk_118', array(['uk_119', 'uk_120', 'uk_123'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_102', 'uk_97', 'uk_101A'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 5 results for vector file cp_sg_uk_vecs_tfidf.npy...\n",
      "Vector file of shape (780, 32516)...\n",
      "{'score': 0.9, 'wrongs': [('sg_140M', 'uk_109', array(['uk_296ZE', 'uk_107', 'uk_198', 'uk_100', 'uk_196'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_102', 'uk_97', 'uk_101A', 'uk_235', 'uk_191M'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 1 results for vector file cp_sg_uk_vecs_ft.npy...\n",
      "Vector file of shape (780, 100)...\n",
      "{'score': 0.25, 'wrongs': [('sg_7A', 'uk_3A', array(['uk_17'], dtype=object)), ('sg_28', 'uk_12', array(['uk_104'], dtype=object)), ('sg_29', 'uk_57', array(['uk_104'], dtype=object)), ('sg_36', 'uk_30', array(['uk_84'], dtype=object)), ('sg_38', 'uk_45', array(['uk_18A'], dtype=object)), ('sg_38A', 'uk_28A', array(['uk_60'], dtype=object)), ('sg_65', 'uk_31', array(['uk_17'], dtype=object)), ('sg_72', 'uk_65', array(['uk_76'], dtype=object)), ('sg_92', 'uk_13A', array(['uk_15'], dtype=object)), ('sg_123', 'uk_101', array(['uk_234'], dtype=object)), ('sg_136', 'uk_107', array(['uk_25'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_100'], dtype=object)), ('sg_160', 'uk_118', array(['uk_119'], dtype=object)), ('sg_197', 'uk_165', array(['uk_106'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_78'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 3 results for vector file cp_sg_uk_vecs_ft.npy...\n",
      "Vector file of shape (780, 100)...\n",
      "{'score': 0.4, 'wrongs': [('sg_7A', 'uk_3A', array(['uk_17', 'uk_21', 'uk_28A'], dtype=object)), ('sg_28', 'uk_12', array(['uk_104', 'uk_106', 'uk_105'], dtype=object)), ('sg_36', 'uk_30', array(['uk_84', 'uk_64', 'uk_60'], dtype=object)), ('sg_38', 'uk_45', array(['uk_18A', 'uk_54', 'uk_34'], dtype=object)), ('sg_38A', 'uk_28A', array(['uk_60', 'uk_84', 'uk_43'], dtype=object)), ('sg_65', 'uk_31', array(['uk_17', 'uk_33', 'uk_175'], dtype=object)), ('sg_92', 'uk_13A', array(['uk_15', 'uk_105', 'uk_166'], dtype=object)), ('sg_123', 'uk_101', array(['uk_234', 'uk_101A', 'uk_191M'], dtype=object)), ('sg_136', 'uk_107', array(['uk_25', 'uk_26', 'uk_60'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_100', 'uk_244', 'uk_151'], dtype=object)), ('sg_197', 'uk_165', array(['uk_106', 'uk_104', 'uk_105'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_78', 'uk_56', 'uk_102'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 5 results for vector file cp_sg_uk_vecs_ft.npy...\n",
      "Vector file of shape (780, 100)...\n",
      "{'score': 0.45, 'wrongs': [('sg_7A', 'uk_3A', array(['uk_17', 'uk_21', 'uk_28A', 'uk_33', 'uk_4'], dtype=object)), ('sg_28', 'uk_12', array(['uk_104', 'uk_106', 'uk_105', 'uk_57', 'uk_93'], dtype=object)), ('sg_36', 'uk_30', array(['uk_84', 'uk_64', 'uk_60', 'uk_76', 'uk_175'], dtype=object)), ('sg_38', 'uk_45', array(['uk_18A', 'uk_54', 'uk_34', 'uk_296ZB', 'uk_60'], dtype=object)), ('sg_38A', 'uk_28A', array(['uk_60', 'uk_84', 'uk_43', 'uk_42', 'uk_42A'], dtype=object)), ('sg_65', 'uk_31', array(['uk_17', 'uk_33', 'uk_175', 'uk_19', 'uk_21'], dtype=object)), ('sg_92', 'uk_13A', array(['uk_15', 'uk_105', 'uk_166', 'uk_5A', 'uk_11'], dtype=object)), ('sg_136', 'uk_107', array(['uk_25', 'uk_26', 'uk_60', 'uk_296ZB', 'uk_83'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_100', 'uk_244', 'uk_151', 'uk_148', 'uk_196'], dtype=object)), ('sg_197', 'uk_165', array(['uk_106', 'uk_104', 'uk_105', 'uk_57', 'uk_93'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_78', 'uk_56', 'uk_102', 'uk_269', 'uk_235'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 1 results for vector file cp_sg_uk_vecs_bert_mlm.npy...\n",
      "Vector file of shape (780, 768)...\n",
      "{'score': 0.4, 'wrongs': [('sg_7A', 'uk_3A', array(['uk_175'], dtype=object)), ('sg_29', 'uk_57', array(['uk_168'], dtype=object)), ('sg_36', 'uk_30', array(['uk_76'], dtype=object)), ('sg_38', 'uk_45', array(['uk_46'], dtype=object)), ('sg_38A', 'uk_28A', array(['uk_29A'], dtype=object)), ('sg_65', 'uk_31', array(['uk_8'], dtype=object)), ('sg_92', 'uk_13A', array(['uk_15'], dtype=object)), ('sg_123', 'uk_101', array(['uk_234'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_296ZEA'], dtype=object)), ('sg_160', 'uk_118', array(['uk_123'], dtype=object)), ('sg_197', 'uk_165', array(['uk_12'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_290'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 3 results for vector file cp_sg_uk_vecs_bert_mlm.npy...\n",
      "Vector file of shape (780, 768)...\n",
      "{'score': 0.55, 'wrongs': [('sg_7A', 'uk_3A', array(['uk_175', 'uk_19', 'uk_28A'], dtype=object)), ('sg_29', 'uk_57', array(['uk_168', 'uk_169', 'uk_104'], dtype=object)), ('sg_36', 'uk_30', array(['uk_76', 'uk_8', 'uk_22'], dtype=object)), ('sg_38A', 'uk_28A', array(['uk_29A', 'uk_12', 'uk_36'], dtype=object)), ('sg_65', 'uk_31', array(['uk_8', 'uk_106', 'uk_130'], dtype=object)), ('sg_92', 'uk_13A', array(['uk_15', 'uk_106', 'uk_168'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_296ZEA', 'uk_47', 'uk_204'], dtype=object)), ('sg_160', 'uk_118', array(['uk_123', 'uk_120', 'uk_141'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_290', 'uk_235', 'uk_239'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting recall at 5 results for vector file cp_sg_uk_vecs_bert_mlm.npy...\n",
      "Vector file of shape (780, 768)...\n",
      "{'score': 0.55, 'wrongs': [('sg_7A', 'uk_3A', array(['uk_175', 'uk_19', 'uk_28A', 'uk_178', 'uk_197'], dtype=object)), ('sg_29', 'uk_57', array(['uk_168', 'uk_169', 'uk_104', 'uk_33', 'uk_10'], dtype=object)), ('sg_36', 'uk_30', array(['uk_76', 'uk_8', 'uk_22', 'uk_10A', 'uk_130'], dtype=object)), ('sg_38A', 'uk_28A', array(['uk_29A', 'uk_12', 'uk_36', 'uk_175', 'uk_80'], dtype=object)), ('sg_65', 'uk_31', array(['uk_8', 'uk_106', 'uk_130', 'uk_46', 'uk_76'], dtype=object)), ('sg_92', 'uk_13A', array(['uk_15', 'uk_106', 'uk_168', 'uk_130', 'uk_216'], dtype=object)), ('sg_140M', 'uk_109', array(['uk_296ZEA', 'uk_47', 'uk_204', 'uk_108', 'uk_114'], dtype=object)), ('sg_160', 'uk_118', array(['uk_123', 'uk_120', 'uk_141', 'uk_138', 'uk_270'], dtype=object)), ('sg_200', 'uk_253C', array(['uk_290', 'uk_235', 'uk_239', 'uk_191M', 'uk_99'], dtype=object))]}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# to get the results the model got wrong printed out\n",
    "evaluate_all(**params, get_wrongs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fce137",
   "metadata": {},
   "source": [
    "### Retriever Function\n",
    "\n",
    "For a more exploratory mode, this retriever function can be used to explore results returned for individual input.\n",
    "\n",
    "This function is also used in the flask application to retrieve matches based on the user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37fcdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with copyright provisions\n",
    "data_path = '../data/clean/copyright/sg_uk_copyright.csv' # this data file will not be pushed to git repo \n",
    "vector_path = '../data/vectors/copyright/cp_sg_uk_vecs_bert_mlm.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2315e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "vectors = np.load(vector_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b533c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_secs = [sec for sec in data[id_col] if juris_A in sec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42b1ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(input_sec, data, vectors, output_juris=juris_B, k=5):\n",
    "    vectors = pd.DataFrame(vectors, index=data[id_col])\n",
    "    juris_split_id = data[data[id_col].str.contains(output_juris)].first_valid_index()\n",
    "    # get the index for when the next jurisdiction entries start \n",
    "    candidate_vecs = vectors[juris_split_id:]\n",
    "    cos_sims = cosine_similarity(\n",
    "            [vectors.loc[input_sec]],\n",
    "            candidate_vecs)\n",
    "    result_ids = (-cos_sims)[0].argsort()[:k]\n",
    "    result_secs = candidate_vecs.iloc[result_ids].index\n",
    "    return {i+1:data[data[id_col]==res][[id_col, 'title', 'url']].to_dict('records')[0] \n",
    "            for i,res in enumerate(result_secs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc1214",
   "metadata": {},
   "source": [
    "Example retrieving a section. Input the section id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8585bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_section = 'sg_50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5646c385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 1 µs, total: 32 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'sec': 'uk_80',\n",
       "  'title': 'Right to object to derogatory treatment of work',\n",
       "  'url': 'www.legislation.gov.uk/ukpga/1988/48/section/80'},\n",
       " 2: {'sec': 'uk_55',\n",
       "  'title': 'Articles for producing material in particular typeface',\n",
       "  'url': 'www.legislation.gov.uk/ukpga/1988/48/section/55'},\n",
       " 3: {'sec': 'uk_77',\n",
       "  'title': 'Right to be identified as author or director',\n",
       "  'url': 'www.legislation.gov.uk/ukpga/1988/48/section/77'},\n",
       " 4: {'sec': 'uk_33',\n",
       "  'title': 'Anthologies for educational use',\n",
       "  'url': 'www.legislation.gov.uk/ukpga/1988/48/section/33'},\n",
       " 5: {'sec': 'uk_175',\n",
       "  'title': 'Meaning of publication and commercial publication',\n",
       "  'url': 'www.legislation.gov.uk/ukpga/1988/48/section/175'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "retrieve(test_input_section, data, vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0588d7f5",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "To keep this notebook clean and reusable for those who would like to try on their own prepared data, the actual results of the project will be consolidated and discussed in the the README instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
