{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab591b9",
   "metadata": {},
   "source": [
    "# Embedding Prep 1b: BERT Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445f661",
   "metadata": {},
   "source": [
    "### Why BERT?\n",
    "\n",
    "Aside from tfidf and fastText embedding methods in the previous notebook, one more method we will try is [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2019)\n",
    "](https://arxiv.org/pdf/1810.04805.pdf). Like fastText, BERT has the ability to encode semantic similarity better than tfidf, but goes one step further by learning the positions of words and having the encoded meaning also dependent on these word positions. In short, BERT has the ability to encode contextual representations, for example learning that the word 'article' in the GDPR has a different meaning from the word 'article' in defamation content talking about newspaper articles.\n",
    "\n",
    "However, \n",
    "\n",
    "For this version, the [bert base uncased model by Hugging Face](https://huggingface.co/bert-base-uncased) was used. Further work trying out other transformer models on Hugging Face is definitely desirable.\n",
    "\n",
    "To pretrain the model to adapt to the language nuances of our legislation data, the BERT model can be pretrained on two tasks, Masked Language Modeling (MLM) and Next Sentence Prediction (NSP). For MLM, 15% of the tokens are masked (hidden) and the model learns through trying to predict these masked tokens. For NSP, the model learns from pairs of sentences where there are examples of sentences that truly follows the first in the pair, and sentences that do not follow, based on the training corpus.\n",
    "\n",
    "The code below will cover both methods, but for the first version of the project, the model pretrained on MLM only was chosen as it performed better than the one that also went through NSP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed056f3",
   "metadata": {},
   "source": [
    "## Expected Output from this Notebook\n",
    "\n",
    "In this notebook, we are embedding our clean data to get vector representations for the legislation sections so that we can match them later on.\n",
    "\n",
    "As such, we expect to get and save from this notebook, the BERT embedding representations of the legislation (.npy file).\n",
    "\n",
    "The outputs below demo based on data for the SG Copyright Act and UK CDPA, but do note as mentioned, the data files containing legislation content will not be in the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed9882",
   "metadata": {},
   "source": [
    "### Specifying Save Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b487009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the output vectors will be saved\n",
    "bert_vector_file = '../data/vectors/copyright/test_saving_bert_vectors.npy'\n",
    "\n",
    "# where the bert model and tokenizer will be saved after pretraining\n",
    "save_model_path = '../models/test_saving_bert_model'\n",
    "save_tokenizer_path = '../models/test_saving_bert_tokenizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c288b6",
   "metadata": {},
   "source": [
    "## Imports and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2edd8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertForPreTraining, AdamW\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d54109",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_filepath = '../data/clean/copyright/sg_uk_copyright.csv' \n",
    "# this data file will not be pushed to git repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9924b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_data_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc480fc2",
   "metadata": {},
   "source": [
    "Prepare content as a list as required for pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b31aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    content = data['cleaned'].to_list()\n",
    "except:\n",
    "    raise Exception('Ensure that the content column to be vectorized is named \"cleaned\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc35780",
   "metadata": {},
   "source": [
    "## MLM Pretraining\n",
    "\n",
    "reference: [this tutorial](https://github.com/jamescalam/transformers/blob/main/course/training/03_mlm_training.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a95d28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16526f",
   "metadata": {},
   "source": [
    "As we will use pytorch, tensors have to be specified as 'pt'. \n",
    "\n",
    "As seen, a large part of our data is around the 400-500 word range, so we will use the largest max langth of 512 tokens, padding the remainder for examples under 512 tokens, as truncating at 512 for those that exceed this length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65d37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(content, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaced51",
   "metadata": {},
   "source": [
    "<a id='create_masks'></a>\n",
    "### Create Labels and Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a65f59",
   "metadata": {},
   "source": [
    "Next, we create a clone of the inputs as the 'answer key' for training our MLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9489019",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25adb8d0",
   "metadata": {},
   "source": [
    "Next we create a mask by initiating a tensor of random values based on the input_id size.\n",
    "\n",
    "From the mask of random values, we will mask 15% of the tokens as done in the BERT paper, while excluding the special CLS (101), SEP (102) and PAD (0) tokens. Essentially we want to be masking actual words rather than these special tokens so that the model is focused on learning from the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b2b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "\n",
    "mask = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727f257",
   "metadata": {},
   "source": [
    "Next, for each sample,  we store the selected indices of masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf4265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ids = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    mask_ids.append(\n",
    "        torch.flatten(mask[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206488f0",
   "metadata": {},
   "source": [
    "We then apply the masks to the respective inputs, with token 103 for masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e047d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, mask_ids[i]] = 103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe4ac1",
   "metadata": {},
   "source": [
    "### Prepare Data and Model for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f91c67",
   "metadata": {},
   "source": [
    "Create Pytorch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d540aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegisDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7eb2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LegisDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b65d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e12d2",
   "metadata": {},
   "source": [
    "### Specify GPU Use\n",
    "This next part allows some flexibility just in case want to train the model using a GPU, for example on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0427527",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7af99bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d0e6d",
   "metadata": {},
   "source": [
    "We make the model trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a71554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b15cc",
   "metadata": {},
   "source": [
    "Next we specify the optimiser, learning rate, and number of epochs to train for.\n",
    "\n",
    "For batch size of 8, use learning rate of 3e-4 (see [here](https://wandb.ai/jack-morris/david-vs-goliath/reports/Does-Model-Size-Matter-A-Comparison-of-BERT-and-DistilBERT--VmlldzoxMDUxNzU))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b460665",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd2c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8375d",
   "metadata": {},
   "source": [
    "<a id='train_model'></a>\n",
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec6ea1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]<ipython-input-11-3813922f0984>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "epoch 0: 100%|██████████| 98/98 [1:17:07<00:00, 47.21s/it, loss=0.146] \n",
      "epoch 1: 100%|██████████| 98/98 [1:10:47<00:00, 43.34s/it, loss=0.115] \n",
      "epoch 2: 100%|██████████| 98/98 [57:01<00:00, 34.91s/it, loss=0.0851] \n",
      "epoch 3: 100%|██████████| 98/98 [55:40<00:00, 34.09s/it, loss=0.0296]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    tq_logger = tqdm(loader, leave=True)\n",
    "    \n",
    "    for batch in tq_logger:\n",
    "        # initiliase gradients\n",
    "        opt.zero_grad()\n",
    "        # move inputs, attn_masks and labels to device like we did for model above\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        \n",
    "        # get computed loss\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        opt.step()\n",
    "\n",
    "        tq_logger.set_description(f'epoch {epoch}')\n",
    "        tq_logger.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following training code instead for NSP+MLM training, after preparing NSP data in the NSP section below.\n",
    "# The main difference is the inclusion of next_sentence_label\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     tq_logger = tqdm(loader, leave=True)\n",
    "    \n",
    "#     for batch in tq_logger:\n",
    "#         # initiliase gradients\n",
    "#         opt.zero_grad()\n",
    "#         # move inputs, attn_masks and labels to device like we did for model above\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, \n",
    "#                         next_sentence_label=next_sentence_label, labels=labels)\n",
    "\n",
    "#         # get computed loss\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "\n",
    "#         # update weights\n",
    "#         opt.step()\n",
    "\n",
    "#         tq_logger.set_description(f'epoch {epoch}')\n",
    "#         tq_logger.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee6290",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eae960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_model_path)\n",
    "tokenizer.save_pretrained(save_tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36385e4",
   "metadata": {},
   "source": [
    "### Get Vectors\n",
    "reference: [this tutorial](https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec9c70",
   "metadata": {},
   "source": [
    "#### Last Hidden State\n",
    "\n",
    "The following code uses the pretrained model to get the vector representations through the last hidden state of the model. The BERT paper has more information about which layer of the model can be chosen for this purpose. \n",
    "\n",
    "For this project, the last hidden state was chosen as the paper shows that it slightly outperforms jsut choosing the first hidden state, while the better performing alternatives require concatenating different hidden states which seems to only marginally perform better but with added complexity.\n",
    "\n",
    "#### Vector Representations\n",
    "\n",
    "For each text, the vector representation of the entire legislation section is computed. This is termed as `sent_vecs` below but is more accurately the vector of all the sentences in the legislation section. These vectors are obtained by summing all the vectors in each token position and dividing it over the amount of tokens where the attention mask is positive.\n",
    "\n",
    "#### Batch Processing\n",
    "\n",
    "The vectors will be processed in small batches to avoid out of memory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c66ec585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 out of 156 batches.\n",
      "Currently at a total of 5 vectors obtained.\n",
      "Processed 2 out of 156 batches.\n",
      "Currently at a total of 10 vectors obtained.\n",
      "Processed 3 out of 156 batches.\n",
      "Currently at a total of 15 vectors obtained.\n",
      "Processed 4 out of 156 batches.\n",
      "Currently at a total of 20 vectors obtained.\n",
      "Processed 5 out of 156 batches.\n",
      "Currently at a total of 25 vectors obtained.\n",
      "Processed 6 out of 156 batches.\n",
      "Currently at a total of 30 vectors obtained.\n",
      "Processed 7 out of 156 batches.\n",
      "Currently at a total of 35 vectors obtained.\n",
      "Processed 8 out of 156 batches.\n",
      "Currently at a total of 40 vectors obtained.\n",
      "Processed 9 out of 156 batches.\n",
      "Currently at a total of 45 vectors obtained.\n",
      "Processed 10 out of 156 batches.\n",
      "Currently at a total of 50 vectors obtained.\n",
      "Processed 11 out of 156 batches.\n",
      "Currently at a total of 55 vectors obtained.\n",
      "Processed 12 out of 156 batches.\n",
      "Currently at a total of 60 vectors obtained.\n",
      "Processed 13 out of 156 batches.\n",
      "Currently at a total of 65 vectors obtained.\n",
      "Processed 14 out of 156 batches.\n",
      "Currently at a total of 70 vectors obtained.\n",
      "Processed 15 out of 156 batches.\n",
      "Currently at a total of 75 vectors obtained.\n",
      "Processed 16 out of 156 batches.\n",
      "Currently at a total of 80 vectors obtained.\n",
      "Processed 17 out of 156 batches.\n",
      "Currently at a total of 85 vectors obtained.\n",
      "Processed 18 out of 156 batches.\n",
      "Currently at a total of 90 vectors obtained.\n",
      "Processed 19 out of 156 batches.\n",
      "Currently at a total of 95 vectors obtained.\n",
      "Processed 20 out of 156 batches.\n",
      "Currently at a total of 100 vectors obtained.\n",
      "Processed 21 out of 156 batches.\n",
      "Currently at a total of 105 vectors obtained.\n",
      "Processed 22 out of 156 batches.\n",
      "Currently at a total of 110 vectors obtained.\n",
      "Processed 23 out of 156 batches.\n",
      "Currently at a total of 115 vectors obtained.\n",
      "Processed 24 out of 156 batches.\n",
      "Currently at a total of 120 vectors obtained.\n",
      "Processed 25 out of 156 batches.\n",
      "Currently at a total of 125 vectors obtained.\n",
      "Processed 26 out of 156 batches.\n",
      "Currently at a total of 130 vectors obtained.\n",
      "Processed 27 out of 156 batches.\n",
      "Currently at a total of 135 vectors obtained.\n",
      "Processed 28 out of 156 batches.\n",
      "Currently at a total of 140 vectors obtained.\n",
      "Processed 29 out of 156 batches.\n",
      "Currently at a total of 145 vectors obtained.\n",
      "Processed 30 out of 156 batches.\n",
      "Currently at a total of 150 vectors obtained.\n",
      "Processed 31 out of 156 batches.\n",
      "Currently at a total of 155 vectors obtained.\n",
      "Processed 32 out of 156 batches.\n",
      "Currently at a total of 160 vectors obtained.\n",
      "Processed 33 out of 156 batches.\n",
      "Currently at a total of 165 vectors obtained.\n",
      "Processed 34 out of 156 batches.\n",
      "Currently at a total of 170 vectors obtained.\n",
      "Processed 35 out of 156 batches.\n",
      "Currently at a total of 175 vectors obtained.\n",
      "Processed 36 out of 156 batches.\n",
      "Currently at a total of 180 vectors obtained.\n",
      "Processed 37 out of 156 batches.\n",
      "Currently at a total of 185 vectors obtained.\n",
      "Processed 38 out of 156 batches.\n",
      "Currently at a total of 190 vectors obtained.\n",
      "Processed 39 out of 156 batches.\n",
      "Currently at a total of 195 vectors obtained.\n",
      "Processed 40 out of 156 batches.\n",
      "Currently at a total of 200 vectors obtained.\n",
      "Processed 41 out of 156 batches.\n",
      "Currently at a total of 205 vectors obtained.\n",
      "Processed 42 out of 156 batches.\n",
      "Currently at a total of 210 vectors obtained.\n",
      "Processed 43 out of 156 batches.\n",
      "Currently at a total of 215 vectors obtained.\n",
      "Processed 44 out of 156 batches.\n",
      "Currently at a total of 220 vectors obtained.\n",
      "Processed 45 out of 156 batches.\n",
      "Currently at a total of 225 vectors obtained.\n",
      "Processed 46 out of 156 batches.\n",
      "Currently at a total of 230 vectors obtained.\n",
      "Processed 47 out of 156 batches.\n",
      "Currently at a total of 235 vectors obtained.\n",
      "Processed 48 out of 156 batches.\n",
      "Currently at a total of 240 vectors obtained.\n",
      "Processed 49 out of 156 batches.\n",
      "Currently at a total of 245 vectors obtained.\n",
      "Processed 50 out of 156 batches.\n",
      "Currently at a total of 250 vectors obtained.\n",
      "Processed 51 out of 156 batches.\n",
      "Currently at a total of 255 vectors obtained.\n",
      "Processed 52 out of 156 batches.\n",
      "Currently at a total of 260 vectors obtained.\n",
      "Processed 53 out of 156 batches.\n",
      "Currently at a total of 265 vectors obtained.\n",
      "Processed 54 out of 156 batches.\n",
      "Currently at a total of 270 vectors obtained.\n",
      "Processed 55 out of 156 batches.\n",
      "Currently at a total of 275 vectors obtained.\n",
      "Processed 56 out of 156 batches.\n",
      "Currently at a total of 280 vectors obtained.\n",
      "Processed 57 out of 156 batches.\n",
      "Currently at a total of 285 vectors obtained.\n",
      "Processed 58 out of 156 batches.\n",
      "Currently at a total of 290 vectors obtained.\n",
      "Processed 59 out of 156 batches.\n",
      "Currently at a total of 295 vectors obtained.\n",
      "Processed 60 out of 156 batches.\n",
      "Currently at a total of 300 vectors obtained.\n",
      "Processed 61 out of 156 batches.\n",
      "Currently at a total of 305 vectors obtained.\n",
      "Processed 62 out of 156 batches.\n",
      "Currently at a total of 310 vectors obtained.\n",
      "Processed 63 out of 156 batches.\n",
      "Currently at a total of 315 vectors obtained.\n",
      "Processed 64 out of 156 batches.\n",
      "Currently at a total of 320 vectors obtained.\n",
      "Processed 65 out of 156 batches.\n",
      "Currently at a total of 325 vectors obtained.\n",
      "Processed 66 out of 156 batches.\n",
      "Currently at a total of 330 vectors obtained.\n",
      "Processed 67 out of 156 batches.\n",
      "Currently at a total of 335 vectors obtained.\n",
      "Processed 68 out of 156 batches.\n",
      "Currently at a total of 340 vectors obtained.\n",
      "Processed 69 out of 156 batches.\n",
      "Currently at a total of 345 vectors obtained.\n",
      "Processed 70 out of 156 batches.\n",
      "Currently at a total of 350 vectors obtained.\n",
      "Processed 71 out of 156 batches.\n",
      "Currently at a total of 355 vectors obtained.\n",
      "Processed 72 out of 156 batches.\n",
      "Currently at a total of 360 vectors obtained.\n",
      "Processed 73 out of 156 batches.\n",
      "Currently at a total of 365 vectors obtained.\n",
      "Processed 74 out of 156 batches.\n",
      "Currently at a total of 370 vectors obtained.\n",
      "Processed 75 out of 156 batches.\n",
      "Currently at a total of 375 vectors obtained.\n",
      "Processed 76 out of 156 batches.\n",
      "Currently at a total of 380 vectors obtained.\n",
      "Processed 77 out of 156 batches.\n",
      "Currently at a total of 385 vectors obtained.\n",
      "Processed 78 out of 156 batches.\n",
      "Currently at a total of 390 vectors obtained.\n",
      "Processed 79 out of 156 batches.\n",
      "Currently at a total of 395 vectors obtained.\n",
      "Processed 80 out of 156 batches.\n",
      "Currently at a total of 400 vectors obtained.\n",
      "Processed 81 out of 156 batches.\n",
      "Currently at a total of 405 vectors obtained.\n",
      "Processed 82 out of 156 batches.\n",
      "Currently at a total of 410 vectors obtained.\n",
      "Processed 83 out of 156 batches.\n",
      "Currently at a total of 415 vectors obtained.\n",
      "Processed 84 out of 156 batches.\n",
      "Currently at a total of 420 vectors obtained.\n",
      "Processed 85 out of 156 batches.\n",
      "Currently at a total of 425 vectors obtained.\n",
      "Processed 86 out of 156 batches.\n",
      "Currently at a total of 430 vectors obtained.\n",
      "Processed 87 out of 156 batches.\n",
      "Currently at a total of 435 vectors obtained.\n",
      "Processed 88 out of 156 batches.\n",
      "Currently at a total of 440 vectors obtained.\n",
      "Processed 89 out of 156 batches.\n",
      "Currently at a total of 445 vectors obtained.\n",
      "Processed 90 out of 156 batches.\n",
      "Currently at a total of 450 vectors obtained.\n",
      "Processed 91 out of 156 batches.\n",
      "Currently at a total of 455 vectors obtained.\n",
      "Processed 92 out of 156 batches.\n",
      "Currently at a total of 460 vectors obtained.\n",
      "Processed 93 out of 156 batches.\n",
      "Currently at a total of 465 vectors obtained.\n",
      "Processed 94 out of 156 batches.\n",
      "Currently at a total of 470 vectors obtained.\n",
      "Processed 95 out of 156 batches.\n",
      "Currently at a total of 475 vectors obtained.\n",
      "Processed 96 out of 156 batches.\n",
      "Currently at a total of 480 vectors obtained.\n",
      "Processed 97 out of 156 batches.\n",
      "Currently at a total of 485 vectors obtained.\n",
      "Processed 98 out of 156 batches.\n",
      "Currently at a total of 490 vectors obtained.\n",
      "Processed 99 out of 156 batches.\n",
      "Currently at a total of 495 vectors obtained.\n",
      "Processed 100 out of 156 batches.\n",
      "Currently at a total of 500 vectors obtained.\n",
      "Processed 101 out of 156 batches.\n",
      "Currently at a total of 505 vectors obtained.\n",
      "Processed 102 out of 156 batches.\n",
      "Currently at a total of 510 vectors obtained.\n",
      "Processed 103 out of 156 batches.\n",
      "Currently at a total of 515 vectors obtained.\n",
      "Processed 104 out of 156 batches.\n",
      "Currently at a total of 520 vectors obtained.\n",
      "Processed 105 out of 156 batches.\n",
      "Currently at a total of 525 vectors obtained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 106 out of 156 batches.\n",
      "Currently at a total of 530 vectors obtained.\n",
      "Processed 107 out of 156 batches.\n",
      "Currently at a total of 535 vectors obtained.\n",
      "Processed 108 out of 156 batches.\n",
      "Currently at a total of 540 vectors obtained.\n",
      "Processed 109 out of 156 batches.\n",
      "Currently at a total of 545 vectors obtained.\n",
      "Processed 110 out of 156 batches.\n",
      "Currently at a total of 550 vectors obtained.\n",
      "Processed 111 out of 156 batches.\n",
      "Currently at a total of 555 vectors obtained.\n",
      "Processed 112 out of 156 batches.\n",
      "Currently at a total of 560 vectors obtained.\n",
      "Processed 113 out of 156 batches.\n",
      "Currently at a total of 565 vectors obtained.\n",
      "Processed 114 out of 156 batches.\n",
      "Currently at a total of 570 vectors obtained.\n",
      "Processed 115 out of 156 batches.\n",
      "Currently at a total of 575 vectors obtained.\n",
      "Processed 116 out of 156 batches.\n",
      "Currently at a total of 580 vectors obtained.\n",
      "Processed 117 out of 156 batches.\n",
      "Currently at a total of 585 vectors obtained.\n",
      "Processed 118 out of 156 batches.\n",
      "Currently at a total of 590 vectors obtained.\n",
      "Processed 119 out of 156 batches.\n",
      "Currently at a total of 595 vectors obtained.\n",
      "Processed 120 out of 156 batches.\n",
      "Currently at a total of 600 vectors obtained.\n",
      "Processed 121 out of 156 batches.\n",
      "Currently at a total of 605 vectors obtained.\n",
      "Processed 122 out of 156 batches.\n",
      "Currently at a total of 610 vectors obtained.\n",
      "Processed 123 out of 156 batches.\n",
      "Currently at a total of 615 vectors obtained.\n",
      "Processed 124 out of 156 batches.\n",
      "Currently at a total of 620 vectors obtained.\n",
      "Processed 125 out of 156 batches.\n",
      "Currently at a total of 625 vectors obtained.\n",
      "Processed 126 out of 156 batches.\n",
      "Currently at a total of 630 vectors obtained.\n",
      "Processed 127 out of 156 batches.\n",
      "Currently at a total of 635 vectors obtained.\n",
      "Processed 128 out of 156 batches.\n",
      "Currently at a total of 640 vectors obtained.\n",
      "Processed 129 out of 156 batches.\n",
      "Currently at a total of 645 vectors obtained.\n",
      "Processed 130 out of 156 batches.\n",
      "Currently at a total of 650 vectors obtained.\n",
      "Processed 131 out of 156 batches.\n",
      "Currently at a total of 655 vectors obtained.\n",
      "Processed 132 out of 156 batches.\n",
      "Currently at a total of 660 vectors obtained.\n",
      "Processed 133 out of 156 batches.\n",
      "Currently at a total of 665 vectors obtained.\n",
      "Processed 134 out of 156 batches.\n",
      "Currently at a total of 670 vectors obtained.\n",
      "Processed 135 out of 156 batches.\n",
      "Currently at a total of 675 vectors obtained.\n",
      "Processed 136 out of 156 batches.\n",
      "Currently at a total of 680 vectors obtained.\n",
      "Processed 137 out of 156 batches.\n",
      "Currently at a total of 685 vectors obtained.\n",
      "Processed 138 out of 156 batches.\n",
      "Currently at a total of 690 vectors obtained.\n",
      "Processed 139 out of 156 batches.\n",
      "Currently at a total of 695 vectors obtained.\n",
      "Processed 140 out of 156 batches.\n",
      "Currently at a total of 700 vectors obtained.\n",
      "Processed 141 out of 156 batches.\n",
      "Currently at a total of 705 vectors obtained.\n",
      "Processed 142 out of 156 batches.\n",
      "Currently at a total of 710 vectors obtained.\n",
      "Processed 143 out of 156 batches.\n",
      "Currently at a total of 715 vectors obtained.\n",
      "Processed 144 out of 156 batches.\n",
      "Currently at a total of 720 vectors obtained.\n",
      "Processed 145 out of 156 batches.\n",
      "Currently at a total of 725 vectors obtained.\n",
      "Processed 146 out of 156 batches.\n",
      "Currently at a total of 730 vectors obtained.\n",
      "Processed 147 out of 156 batches.\n",
      "Currently at a total of 735 vectors obtained.\n",
      "Processed 148 out of 156 batches.\n",
      "Currently at a total of 740 vectors obtained.\n",
      "Processed 149 out of 156 batches.\n",
      "Currently at a total of 745 vectors obtained.\n",
      "Processed 150 out of 156 batches.\n",
      "Currently at a total of 750 vectors obtained.\n",
      "Processed 151 out of 156 batches.\n",
      "Currently at a total of 755 vectors obtained.\n",
      "Processed 152 out of 156 batches.\n",
      "Currently at a total of 760 vectors obtained.\n",
      "Processed 153 out of 156 batches.\n",
      "Currently at a total of 765 vectors obtained.\n",
      "Processed 154 out of 156 batches.\n",
      "Currently at a total of 770 vectors obtained.\n",
      "Processed 155 out of 156 batches.\n",
      "Currently at a total of 775 vectors obtained.\n",
      "Processed 156 out of 156 batches.\n",
      "Currently at a total of 780 vectors obtained.\n"
     ]
    }
   ],
   "source": [
    "process_batch_size = 5\n",
    "max_batches = len(content) // process_batch_size\n",
    "remainder = len(content) % process_batch_size\n",
    "processed_batches = 0\n",
    "batch_start = 0\n",
    "batch_stop = batch_start + process_batch_size\n",
    "\n",
    "while processed_batches < max_batches:\n",
    "    \n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "    \n",
    "    if max_batches - processed_batches == 1:\n",
    "        batch_stop += remainder\n",
    "    \n",
    "    for legis in content[batch_start:batch_stop]:\n",
    "        new_tokens = tokenizer.encode_plus(legis, max_length=512,\n",
    "                                           truncation=True, padding='max_length',\n",
    "                                           return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "    # reformat list of tensors into single tensor\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "    \n",
    "    outputs = model(**tokens, output_hidden_states=True)\n",
    "    embeddings = outputs['hidden_states'][-1]\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    masked_embeddings = embeddings * mask\n",
    "    summed = torch.sum(masked_embeddings, 1)\n",
    "    # set a minimum of 0.0001 to avoid zero division\n",
    "    summed_mask = torch.clamp(mask.sum(1), min=0.0001)\n",
    "    # get the sentence vectors from the mean pool\n",
    "    sent_vecs = summed / summed_mask\n",
    "    sent_vecs = sent_vecs.detach().numpy()\n",
    "    \n",
    "    if batch_start == 0:\n",
    "        all_sent_vecs = sent_vecs\n",
    "    else:\n",
    "        all_sent_vecs = np.concatenate((all_sent_vecs, sent_vecs), axis=0)\n",
    "    \n",
    "    batch_start += process_batch_size\n",
    "    batch_stop += process_batch_size\n",
    "    processed_batches += 1\n",
    "    print(f'Processed {processed_batches} out of {max_batches} batches.')\n",
    "    print(f'Currently at a total of {all_sent_vecs.shape[0]} vectors obtained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b05753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f5580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(bert_vector_file, all_sent_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2137b",
   "metadata": {},
   "source": [
    "## MLM and NSP PreTraining\n",
    "reference: [this tutorial](https://www.youtube.com/watch?v=IC9FaVPKlYc) \n",
    "\n",
    "The code is for pretraining using both MLM and NSP tasks. In this project, it was found that the MLM only vectors somehow performed better than those from a model pretrained with both MLM and NSP tasks. Since MLM-only performed better and was faster to train, NSP was not used.\n",
    "\n",
    "However, this could just be due to the specific quirks of the evaluation data or perhaps some issue with the data cleaning.\n",
    "\n",
    "For those trying out on their own data, both methods should definitely be tried. According to the BERT paper authors, NSP should ideally allow the model to learn context better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344e9d4",
   "metadata": {},
   "source": [
    "### Prepare Sentences for NSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cbef4d",
   "metadata": {},
   "source": [
    "Prepare a bag of sentences where we can select our random negative examples from later. Essentially getting each legislation provision `legis` and splitting into sentences.\n",
    "\n",
    "To keep this lightweight, we just split on fullstops. To be more pedantic, a tokenizer from an nlp library like spaCy or NLTK could also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f166964",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = [sentence for legis in content for sentence in legis.split('. ') if sentence != '']\n",
    "all_len = len(all_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d3a3b",
   "metadata": {},
   "source": [
    "Create NSP training data. The first sentence, second sentence, and labels for each pair. Label 0 is when second sentence follows first, label 1 when second sentence does not follow first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f81347",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = []\n",
    "sentence_2 = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b482a0",
   "metadata": {},
   "source": [
    "Next, generate the next sentence pairs with an even mix of sentences that follow, and sentences that don't. Sentences that do not follow are sampled from the all_sentences list above. We iterate through each legis entry to get our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1492d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for legis in content:\n",
    "    sentences = [sentence for sentence in legis.split('. ') if sentence != '']\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1: # we can only get a correct next sentence if there are multiple sentences\n",
    "        start = random.randint(0, num_sentences-2) # randomly sample a sentence except the last one\n",
    "        sentence_1.append(sentences[start])\n",
    "        next_sent = sentences[start+1]\n",
    "        if random.random() > 0.5:\n",
    "            # 50% chance of generating a correct NSP example\n",
    "            sentence_2.append(next_sent)\n",
    "            label.append(0)\n",
    "        else:\n",
    "            # 50% chance of generating a wrong NSP example\n",
    "            wrong_sent = all_sentences[random.randint(0, all_len-1)]\n",
    "            # ensure our wrong example sentences is indeed wrong\n",
    "            while wrong_sent == next_sent:\n",
    "                wrong_sent = all_sentences[random.randint(0, all_len-1)]\n",
    "            sentence_2.append(wrong_sent)\n",
    "            label.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd749c4b",
   "metadata": {},
   "source": [
    "We can examine our sentence pairs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10,15):\n",
    "#     print(i, sentence_1[i], '----next_sent----', sentence_2[i], '----label----', label[i], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c318a",
   "metadata": {},
   "source": [
    "Use `BertForPreTraining` for MLM and NSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4804dcb",
   "metadata": {},
   "source": [
    "Prepare the the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_1, sentence_2, \n",
    "                   return_tensors='pt', max_length=512, \n",
    "                   truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568a6195",
   "metadata": {},
   "source": [
    "The next part is to prepare the MLM portion exactly as above. \n",
    "\n",
    "Just proceed to run the code from [the Create Labels and Masks cell](#create_masks) onwards (preparing, training model etc) all the way till the vectors are created and saved. Be sure to use the correct code in the [train model section](#train_model), which is commented out for MLM-only training. A larger batch size might be recommended with the learning rate changed accordingly. For this project, when NSP-MLM tried was 16 instead of 8, the loss managed to go down lower, while it was struggling to do so at batch size 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d71f5",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee08c8",
   "metadata": {},
   "source": [
    "BERT paper: \n",
    "- https://arxiv.org/pdf/1810.04805.pdf\n",
    "\n",
    "Pretraining BERT in PyTorch and getting vectors:\n",
    "- https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1\n",
    "- https://github.com/jamescalam/transformers/blob/main/course/training/03_mlm_training.ipynb\n",
    "- https://www.youtube.com/watch?v=IC9FaVPKlYc\n",
    "\n",
    "BERT learning rates:\n",
    "- https://wandb.ai/jack-morris/david-vs-goliath/reports/Does-Model-Size-Matter-A-Comparison-of-BERT-and-DistilBERT--VmlldzoxMDUxNzU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
