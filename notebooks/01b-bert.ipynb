{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ec369f",
   "metadata": {},
   "source": [
    "# Embedding Prep 1b: BERT Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276df5f7",
   "metadata": {},
   "source": [
    "### Why BERT?\n",
    "\n",
    "Aside from tfidf and fastText embedding methods in the previous notebook, one more method we will try is [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2019)\n",
    "](https://arxiv.org/pdf/1810.04805.pdf). Like fastText, BERT has the ability to encode semantic similarity better than tfidf, but goes one step further by learning the positions of words and having the encoded meaning also dependent on these word positions. In short, BERT has the ability to encode contextual representations, for example learning that the word 'article' in the GDPR has a different meaning from the word 'article' in defamation content talking about newspaper articles.\n",
    "\n",
    "However, \n",
    "\n",
    "For this version, the [bert base uncased model by Hugging Face](https://huggingface.co/bert-base-uncased) was used. Further work trying out other transformer models on Hugging Face is definitely desirable.\n",
    "\n",
    "To pretrain the model to adapt to the language nuances of our legislation data, the BERT model can be pretrained on two tasks, Masked Language Modeling (MLM) and Next Sentence Prediction (NSP). For MLM, 15% of the tokens are masked (hidden) and the model learns through trying to predict these masked tokens. For NSP, the model learns from pairs of sentences where there are examples of sentences that truly follows the first in the pair, and sentences that do not follow, based on the training corpus.\n",
    "\n",
    "The code below will cover both methods, but for the first version of the project, the model pretrained on MLM only was chosen as it performed better than the one that also went through NSP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea729e74",
   "metadata": {},
   "source": [
    "## Expected Output from this Notebook\n",
    "\n",
    "In this notebook, we are embedding our clean data to get vector representations for the legislation sections so that we can match them later on.\n",
    "\n",
    "As such, we expect to get and save from this notebook, the BERT embedding representations of the legislation (.npy file).\n",
    "\n",
    "The outputs below demo based on data for the SG Copyright Act and UK CDPA, but do note as mentioned, the data files containing legislation content will not be in the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87240c62",
   "metadata": {},
   "source": [
    "### Specifying Save Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the output vectors will be saved\n",
    "bert_vector_file = '../data/vectors/copyright/test_saving_bert_vectors.npy'\n",
    "\n",
    "# where the bert model and tokenizer will be saved after pretraining\n",
    "save_model_path = '../models/test_saving_bert_model'\n",
    "save_tokenizer_path = '../models/test_saving_bert_tokenizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e5e11",
   "metadata": {},
   "source": [
    "## Imports and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fdf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertForPreTraining, AdamW\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ed4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_filepath = '../data/clean/copyright/sg_uk_copyright.csv' \n",
    "# this data file will not be pushed to git repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9507f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_data_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafa702",
   "metadata": {},
   "source": [
    "Prepare content as a list as required for pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fd43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    content = data['cleaned'].to_list()\n",
    "except:\n",
    "    raise Exception('Ensure that the content column to be vectorized is named \"cleaned\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37abb85",
   "metadata": {},
   "source": [
    "## MLM Pretraining\n",
    "\n",
    "reference: [this tutorial](https://github.com/jamescalam/transformers/blob/main/course/training/03_mlm_training.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c991a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640d720",
   "metadata": {},
   "source": [
    "As we will use pytorch, tensors have to be specified as 'pt'. \n",
    "\n",
    "As seen, a large part of our data is around the 400-500 word range, so we will use the largest max langth of 512 tokens, padding the remainder for examples under 512 tokens, as truncating at 512 for those that exceed this length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb3acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(content, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c50d4",
   "metadata": {},
   "source": [
    "<a id='create_masks'></a>\n",
    "### Create Labels and Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae266b0",
   "metadata": {},
   "source": [
    "Next, we create a clone of the inputs as the 'answer key' for training our MLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ebd048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9aa012",
   "metadata": {},
   "source": [
    "Next we create a mask by initiating a tensor of random values based on the input_id size.\n",
    "\n",
    "From the mask of random values, we will mask 15% of the tokens as done in the BERT paper, while excluding the special CLS (101), SEP (102) and PAD (0) tokens. Essentially we want to be masking actual words rather than these special tokens so that the model is focused on learning from the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "\n",
    "mask = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc23d9",
   "metadata": {},
   "source": [
    "Next, for each sample,  we store the selected indices of masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54019d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ids = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    mask_ids.append(\n",
    "        torch.flatten(mask[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf929e",
   "metadata": {},
   "source": [
    "We then apply the masks to the respective inputs, with token 103 for masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a09938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, mask_ids[i]] = 103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6356cdf0",
   "metadata": {},
   "source": [
    "### Prepare Data and Model for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4730e",
   "metadata": {},
   "source": [
    "Create Pytorch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25a4a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegisDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e223254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LegisDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6939b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bc75b",
   "metadata": {},
   "source": [
    "### Specify GPU Use\n",
    "This next part allows some flexibility just in case want to train the model using a GPU, for example on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c171607",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0574c673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd791b9",
   "metadata": {},
   "source": [
    "We make the model trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0044a47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e355ea9",
   "metadata": {},
   "source": [
    "Next we specify the optimiser, learning rate, and number of epochs to train for.\n",
    "\n",
    "For batch size of 8, use learning rate of 3e-4 (see [here](https://wandb.ai/jack-morris/david-vs-goliath/reports/Does-Model-Size-Matter-A-Comparison-of-BERT-and-DistilBERT--VmlldzoxMDUxNzU))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfcf8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae5b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fdbbec",
   "metadata": {},
   "source": [
    "<a id='train_model'></a>\n",
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ce4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]<ipython-input-11-3813922f0984>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "epoch 0: 100%|██████████| 98/98 [1:17:07<00:00, 47.21s/it, loss=0.146] \n",
      "epoch 1:  61%|██████    | 60/98 [43:31<26:00, 41.05s/it, loss=0.0525]  "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    tq_logger = tqdm(loader, leave=True)\n",
    "    \n",
    "    for batch in tq_logger:\n",
    "        # initiliase gradients\n",
    "        opt.zero_grad()\n",
    "        # move inputs, attn_masks and labels to device like we did for model above\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        \n",
    "        # get computed loss\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        opt.step()\n",
    "\n",
    "        tq_logger.set_description(f'epoch {epoch}')\n",
    "        tq_logger.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c34095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following training code instead for NSP+MLM training, after preparing NSP data in the NSP section below.\n",
    "# The main difference is the inclusion of next_sentence_label\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     tq_logger = tqdm(loader, leave=True)\n",
    "    \n",
    "#     for batch in tq_logger:\n",
    "#         # initiliase gradients\n",
    "#         opt.zero_grad()\n",
    "#         # move inputs, attn_masks and labels to device like we did for model above\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask, \n",
    "#                         next_sentence_label=next_sentence_label, labels=labels)\n",
    "\n",
    "#         # get computed loss\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "\n",
    "#         # update weights\n",
    "#         opt.step()\n",
    "\n",
    "#         tq_logger.set_description(f'epoch {epoch}')\n",
    "#         tq_logger.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e6b8f",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_model_path)\n",
    "tokenizer.save_pretrained(save_tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287e93a",
   "metadata": {},
   "source": [
    "### Get Vectors\n",
    "reference: [this tutorial](https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee6e37",
   "metadata": {},
   "source": [
    "#### Last Hidden State\n",
    "\n",
    "The following code uses the pretrained model to get the vector representations through the last hidden state of the model. The BERT paper has more information about which layer of the model can be chosen for this purpose. \n",
    "\n",
    "For this project, the last hidden state was chosen as the paper shows that it slightly outperforms jsut choosing the first hidden state, while the better performing alternatives require concatenating different hidden states which seems to only marginally perform better but with added complexity.\n",
    "\n",
    "#### Vector Representations\n",
    "\n",
    "For each text, the vector representation of the entire legislation section is computed. This is termed as `sent_vecs` below but is more accurately the vector of all the sentences in the legislation section. These vectors are obtained by summing all the vectors in each token position and dividing it over the amount of tokens where the attention mask is positive.\n",
    "\n",
    "#### Batch Processing\n",
    "\n",
    "The vectors will be processed in small batches to avoid out of memory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_batch_size = 5\n",
    "max_batches = len(content) // process_batch_size\n",
    "remainder = len(content) % process_batch_size\n",
    "processed_batches = 0\n",
    "batch_start = 0\n",
    "batch_stop = batch_start + process_batch_size\n",
    "\n",
    "while processed_batches < max_batches:\n",
    "    \n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "    \n",
    "    if max_batches - processed_batches == 1:\n",
    "        batch_stop += remainder\n",
    "    \n",
    "    for legis in content[batch_start:batch_stop]:\n",
    "        new_tokens = tokenizer.encode_plus(legis, max_length=512,\n",
    "                                           truncation=True, padding='max_length',\n",
    "                                           return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "    # reformat list of tensors into single tensor\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "    \n",
    "    outputs = model(**tokens, output_hidden_states=True)\n",
    "    embeddings = outputs['hidden_states'][-1]\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    masked_embeddings = embeddings * mask\n",
    "    summed = torch.sum(masked_embeddings, 1)\n",
    "    # set a minimum of 0.0001 to avoid zero division\n",
    "    summed_mask = torch.clamp(mask.sum(1), min=0.0001)\n",
    "    # get the sentence vectors from the mean pool\n",
    "    sent_vecs = summed / summed_mask\n",
    "    sent_vecs = sent_vecs.detach().numpy()\n",
    "    \n",
    "    if batch_start == 0:\n",
    "        all_sent_vecs = sent_vecs\n",
    "    else:\n",
    "        all_sent_vecs = np.concatenate((all_sent_vecs, sent_vecs), axis=0)\n",
    "    \n",
    "    batch_start += process_batch_size\n",
    "    batch_stop += process_batch_size\n",
    "    processed_batches += 1\n",
    "    print(f'Processed {processed_batches} out of {max_batches} batches.')\n",
    "    print(f'Currently at a total of {all_sent_vecs.shape[0]} vectors obtained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058af5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(bert_vector_file, all_sent_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc9fe4",
   "metadata": {},
   "source": [
    "## MLM and NSP PreTraining\n",
    "reference: [this tutorial](https://www.youtube.com/watch?v=IC9FaVPKlYc) \n",
    "\n",
    "The code is for pretraining using both MLM and NSP tasks. In this project, it was found that the MLM only vectors somehow performed better than those from a model pretrained with both MLM and NSP tasks. Since MLM-only performed better and was faster to train, NSP was not used.\n",
    "\n",
    "However, this could just be due to the specific quirks of the evaluation data or perhaps some issue with the data cleaning.\n",
    "\n",
    "For those trying out on their own data, both methods should definitely be tried. According to the BERT paper authors, NSP should ideally allow the model to learn context better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83593e5",
   "metadata": {},
   "source": [
    "### Prepare Sentences for NSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc947abe",
   "metadata": {},
   "source": [
    "Prepare a bag of sentences where we can select our random negative examples from later. Essentially getting each legislation provision `legis` and splitting into sentences.\n",
    "\n",
    "To keep this lightweight, we just split on fullstops. To be more pedantic, a tokenizer from an nlp library like spaCy or NLTK could also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = [sentence for legis in content for sentence in legis.split('. ') if sentence != '']\n",
    "all_len = len(all_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7342021",
   "metadata": {},
   "source": [
    "Create NSP training data. The first sentence, second sentence, and labels for each pair. Label 0 is when second sentence follows first, label 1 when second sentence does not follow first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = []\n",
    "sentence_2 = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9e293",
   "metadata": {},
   "source": [
    "Next, generate the next sentence pairs with an even mix of sentences that follow, and sentences that don't. Sentences that do not follow are sampled from the all_sentences list above. We iterate through each legis entry to get our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for legis in content:\n",
    "    sentences = [sentence for sentence in legis.split('. ') if sentence != '']\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1: # we can only get a correct next sentence if there are multiple sentences\n",
    "        start = random.randint(0, num_sentences-2) # randomly sample a sentence except the last one\n",
    "        sentence_1.append(sentences[start])\n",
    "        next_sent = sentences[start+1]\n",
    "        if random.random() > 0.5:\n",
    "            # 50% chance of generating a correct NSP example\n",
    "            sentence_2.append(next_sent)\n",
    "            label.append(0)\n",
    "        else:\n",
    "            # 50% chance of generating a wrong NSP example\n",
    "            wrong_sent = all_sentences[random.randint(0, all_len-1)]\n",
    "            # ensure our wrong example sentences is indeed wrong\n",
    "            while wrong_sent == next_sent:\n",
    "                wrong_sent = all_sentences[random.randint(0, all_len-1)]\n",
    "            sentence_2.append(wrong_sent)\n",
    "            label.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740a735",
   "metadata": {},
   "source": [
    "We can examine our sentence pairs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14740314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10,15):\n",
    "#     print(i, sentence_1[i], '----next_sent----', sentence_2[i], '----label----', label[i], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636cff66",
   "metadata": {},
   "source": [
    "Use `BertForPreTraining` for MLM and NSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce2faa",
   "metadata": {},
   "source": [
    "Prepare the the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafcb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_1, sentence_2, \n",
    "                   return_tensors='pt', max_length=512, \n",
    "                   truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd42790",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e78da1",
   "metadata": {},
   "source": [
    "The next part is to prepare the MLM portion exactly as above. \n",
    "\n",
    "Just proceed to run the code from [the Create Labels and Masks cell](#create_masks) onwards (preparing, training model etc) all the way till the vectors are created and saved. Be sure to use the correct code in the [train model section](#train_model), which is commented out for MLM-only training. A larger batch size might be recommended with the learning rate changed accordingly. For this project, when NSP-MLM tried was 16 instead of 8, the loss managed to go down lower, while it was struggling to do so at batch size 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b88c6b",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a8c60",
   "metadata": {},
   "source": [
    "BERT paper: \n",
    "- https://arxiv.org/pdf/1810.04805.pdf\n",
    "\n",
    "Pretraining BERT in PyTorch and getting vectors:\n",
    "- https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1\n",
    "- https://github.com/jamescalam/transformers/blob/main/course/training/03_mlm_training.ipynb\n",
    "- https://www.youtube.com/watch?v=IC9FaVPKlYc\n",
    "\n",
    "BERT learning rates:\n",
    "- https://wandb.ai/jack-morris/david-vs-goliath/reports/Does-Model-Size-Matter-A-Comparison-of-BERT-and-DistilBERT--VmlldzoxMDUxNzU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
