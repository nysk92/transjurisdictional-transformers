{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4449d849",
   "metadata": {},
   "source": [
    "# Transjurisdictional Transformers\n",
    "Helping lawyers quickly find similar legislation from another jurisdiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4260e3",
   "metadata": {},
   "source": [
    "### Problem Statement and Background\n",
    "\n",
    "Lawyers engaged in cross-jurisdictional work might have to quickly familiarise themselves with legal positions in a few jurisdictions. These different jurisdictions may have statutes covering similar points of law, but may not use consistent wording. Note that the actual legal requirements may differ between jurisdictions, the provisions are analogous (think about the piece of legislation on mask wearing in Singapore vs that in UK).\n",
    "\n",
    "Lawyers may have to go through a tedious process of finding out which are the analogous positions on a point of law in a different jurisdiction either through initial background research on cross-jurisdiction comparison articles, or simply manually comb through the different statutes. \n",
    "\n",
    "The hypothesis is that helping lawyers quickly get to the analogous provisions in another jurisdiction can be sped up using natural language processing techniques that encode semantic similarity.\n",
    "\n",
    "### Project Goals\n",
    "\n",
    "This is a project aimed at helping lawyers doing cross-jurisdictional research by helping them quickly match a legislation provision of interest to its equivalent in another jurisdiction. The matching will be done on a semantic level, using vector similarity, specifically on cosine similarity.\n",
    "\n",
    "To achieve this, several methods for embedding each legislative provision will be used and the outcome will be evaluated on some prepared positive match examples. \n",
    "\n",
    "The embedding methods tried will be:\n",
    "- tfidf (term frequency inverse document frequency)\n",
    "- fastText\n",
    "- BERT\n",
    "\n",
    "And a baseline performance will be calculated based on edit distance between the titles of the legislation sections.\n",
    "\n",
    "### Scope\n",
    "\n",
    "For the scope of the first version of this project, each dataset will only contain one legislation from each jurisdiction, and the legislations covered are:\n",
    "- Singapore Copyright Act & UK Copyright, Designs and Patents Act (CDPA)\n",
    "- Singapore and UK Trade Marks Acts\n",
    "- Singapore Personal Data Protection Act and European Union (EU) General Data Protection Regulation (GDPR)\n",
    "\n",
    "The matching will be done on a section level. For the purposes of this project, articles in the GDPR will be treated as sections.\n",
    "\n",
    "### Adaptability\n",
    "\n",
    "Although the scope of this project is limited to the legislations mentioned above, the limitation comes more from the time needed to annotate examples for meaningful evaluation rather than any technical limitation on data volume.\n",
    "\n",
    "The code in these notebooks is written in a way to allow it to be as reusable as possible for anyone to try their own legislation matching with these embedding methods once they have prepared their legislation data in the required input format.\n",
    "\n",
    "```\n",
    "required_input_cols = [id_col, 'title', 'url', 'cleaned']\n",
    "```\n",
    "For users wishing to expand the scope of this application, the `id_col` can be named to something more appropriate than 'sec', and the format for creating id numbers can be more sophisticated to account for multiple legislation per jurisdiction, or different provision granularity like divisions or subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037f055",
   "metadata": {},
   "source": [
    "# Embedding Prep 1a: Baselines, tfidf Vectors, and fastText Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867ba75",
   "metadata": {},
   "source": [
    "This notebook will cover getting tfidf and fastText embeddings, as well as computing the edit distance of titles based on the levenshtein distance.\n",
    "\n",
    "The edit distance between titles simulates lawyers simply eyeballing similar or identical section titles to find the closest match across jurisdictions. Analagously, if our embedding methods cannot outperform the baseline, a lawyer might as well quickly scan through or hopefully ctrl-f through for similar looking titles themselves to find equivalent legislation.\n",
    "\n",
    "### Why tfidf?\n",
    "We are trying tfidf as it is relatively simple to compute representation of the legislative text. tfidf is commonly used in many search engines and to featurise data for other downstream machine learning tasks like text classification. Its reliability over the years is also thanks to its robustness on longer texts, likely due to the term frequency element that considers the count of the terms versus the document length. \n",
    "\n",
    "One drawback of tfidf however, is that it does encode semantically similarity between synonymous terms, as each word/phrase is a separate feature in the matrix no matter how similar their meanings are. This could be an obstacle for this project if the two jurisdictions use very different terms to express the same legal concepts.\n",
    "\n",
    "### Why fastText?\n",
    "\n",
    "see [Enriching Word Vectors with Subword Information (Bojanowski et al., 2016)](https://arxiv.org/pdf/1607.04606v2.pdf)\n",
    "\n",
    "fastText is a word embedding method that is similar to word2vec, but has added character level ngram representations that can preserve subword information. Like word2vec, the word representations are trained with a continuous bag of word or skipgram methods, in which the representation of a word is learned by the words occuring around it in the training corpus.\n",
    "\n",
    "Theoretically, this should overcome the tfidf weakness of not being able to encode semantic similarity. Ideally, fastText should perform well on capturing similar meaning between legislation sections that do not necessarily use the exact same words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20440e8",
   "metadata": {},
   "source": [
    "## Expected Output from this Notebook\n",
    "\n",
    "In this notebook, we are embedding our clean data to get vector representations for the legislation sections so that we can match them later on.\n",
    "\n",
    "As such, these are the outputs we expect to get and save from this notebook:\n",
    "- title edit distance scores, serving as our baseline (csv file)\n",
    "- tfidf vectors representing each legislation (npy file)\n",
    "- fasttext vectors representing each legislation (npy file)\n",
    "\n",
    "The outputs below demo based on data for the SG Copyright Act and UK CDPA, but do note as mentioned, the data files containing legislation content will not be in the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96027e1b",
   "metadata": {},
   "source": [
    "### Specifying Save Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071f7483",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_distance_file = '../data/baselines/test_saving_copyright_levdists.csv'\n",
    "tfidf_vector_file = '../data/vectors/copyright/test_saving_cp_sg_uk_vecs_tfidf.npy'\n",
    "ft_vector_file = '../data/vectors/copyright/test_saving_cp_sg_uk_vecs_ft.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abdb32a",
   "metadata": {},
   "source": [
    "## Imports and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f42410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk import edit_distance\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d156765",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'sec'\n",
    "required_input_cols = [id_col, 'title', 'url', 'cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60af5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_filepath = '../data/clean/copyright/sg_uk_copyright.csv' \n",
    "# this data file will not be pushed to git repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc43076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46ff4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = data[required_input_cols]\n",
    "except KeyError:\n",
    "    raise Exception('Ensure that the input data contains all the columns specified in required_input_cols.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9c186",
   "metadata": {},
   "source": [
    "## Computing Baseline on Title Edit Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000c654",
   "metadata": {},
   "source": [
    "Our baseline will be later computed based on the edit (levenshtein) distance between legislation section titles. To prepare for that evaluation, we create a matrix that contains each entry's title's edit distance to every other entry's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad492d8d",
   "metadata": {},
   "source": [
    "X represent what will be our edit distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59fd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e93d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, pd.DataFrame(np.zeros((data.shape[0], data.shape[0])))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8443becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:, 1:] = data['title'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b98ab2",
   "metadata": {},
   "source": [
    "Compute levenshtein distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5dd1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in X.iterrows():\n",
    "    main_text = row.iloc[0]\n",
    "    for i, c in enumerate(row.iloc[1:]):\n",
    "        row.iloc[1+i] = edit_distance(main_text, c)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f872ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lds = X.drop(columns='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dbeca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lds = result_lds.set_index(data[id_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26efebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lds = result_lds.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c515b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mapper = dict(zip(result_lds.columns, result_lds.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9163662",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lds = result_lds.rename(columns=col_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f29a86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 780)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04076bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lds.to_csv(edit_distance_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a4cd5",
   "metadata": {},
   "source": [
    "## Preparing tfidf Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056881f3",
   "metadata": {},
   "source": [
    "max_df of 0.95 is used to filter out very common words, hopefully getting rid of stopwords thus not requiring us to load a stopwords file. We use an ngram range of (1,2) as legal terms are important in context, but preferably staying below 3 so as to not bloat the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a37f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(ngram_range=(1,2), max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b0f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv_matrix = tfv.fit_transform(data['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66bb299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv_matrix = tfv_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f735f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(tfidf_vector_file, tfv_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cb4be",
   "metadata": {},
   "source": [
    "## Preparing fastText Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e3fd9",
   "metadata": {},
   "source": [
    "To train a fastText model with our data, the content must be converted to txt format as required by fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7770888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path where the processed txt data will sit\n",
    "# this is path that fastText will use to train the model too\n",
    "ft_filename = '../data/clean/copyright/sg_uk_copyright.txt'\n",
    "\n",
    "# this txt file will not be pushed to the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4bcf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our dataframe content entries to txt\n",
    "with open(ft_filename, 'w') as f:\n",
    "    for entry in data['cleaned'].values:\n",
    "        f.write(entry)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a7869",
   "metadata": {},
   "source": [
    "### fastText Params\n",
    "The following params seemed to produce a decent model for the copyright and trade mark examples. However, more time can be spent tweaking the [hyperparams](https://fasttext.cc/docs/en/python-module.html#api) to get better perfomance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe3e3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordNgrams = 2\n",
    "ft_model_type = 'skipgram' # skipgram or cbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f47d0a",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8439324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ft.train_unsupervised(ft_filename, model=ft_model_type, wordNgrams=wordNgrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49d595",
   "metadata": {},
   "source": [
    "For data protection, these model hyperparams appear to perform better than the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ft.train_unsupervised(filename, dim=50, \n",
    "#                               lr=0.0001, epoch=50, \n",
    "#                               minn=6, minCount=3, ws=10,\n",
    "#                               model='skipgram', wordNgrams=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e7f62",
   "metadata": {},
   "source": [
    "There is an option to use pretrained Wikipedia weights, simply download from the [here](https://fasttext.cc/docs/en/english-vectors.html).\n",
    "\n",
    "However, for the scope of this project, the pretrained weights did not signficantly improve performance, and require a huge model file of a few GB to be stored, and so are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42baf0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_model_path = ''\n",
    "# model = ft.load_model(wiki_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7fedd",
   "metadata": {},
   "source": [
    "### Get Sentence Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the GDPR data, this further cleaning was required for the sentence vectorisation to work\n",
    "# data['cleaned'] = data['cleaned'].map(lambda x: x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a615f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs = [model.get_sentence_vector(s) for s in data['cleaned'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73fb44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(ft_vector_file, sent_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "652e94c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f806de0",
   "metadata": {},
   "source": [
    "### Additional Notes on fastText\n",
    "\n",
    "fastText does not require your data to be lower-cased, neither does it do so for you automatically.\n",
    "Lower casing the data does not necessarily improve performance, and in this project, a lower-cased version was tried and the results did not improve.\n",
    "\n",
    "To try it out yourself, simply lowercase both the training data and data to be vectorized.\n",
    "\n",
    "```\n",
    "with open(ft_filename, 'w') as f:\n",
    "    for entry in data['cleaned'].values:\n",
    "        f.write(entry.lower())\n",
    "        f.write('\\n\\n')\n",
    "...\n",
    "\n",
    "sent_vecs = [model.get_sentence_vector(s.lower()) for s in data['cleaned'].values]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2699c6",
   "metadata": {},
   "source": [
    "## Next Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd80a0",
   "metadata": {},
   "source": [
    "In notebook 1b, vectors from a BERT model will be prepared. It is done in a separate notebook to facilitate easy optional training on cloud GPUs.\n",
    "\n",
    "In notebook 2, the vectors can be evluated according to answer keys after being matches on cosine similarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
